{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Recognition\n",
    "\n",
    "The objective of this lab is very simple, to recognize objects in images. You will be working with a well-known dataset called CIFAR-10.\n",
    "\n",
    "You can learn more about this dataset and download it here:\n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "In the webpage above, they also included a few publications based on CIFAR-10 data, which showed some amazing accuracies. The worst network on the page (a shallow convolutional neural network) can classify images with rouhgly 75% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Write a function to load data\n",
    "\n",
    "The dataset webpage in the previous section also provide a simple way to load data from your harddrive using pickle. You may use their function for this exercise.\n",
    "\n",
    "Construct two numpy arrays for train images and train labels from data_batch_1 to data_batch_5. Then, construct two numpy arrays for test images, and test labels from test batch file. The original image size is 32 x 32 x 3. You may flatten the arrays so the final arrays are of size 1 x 3072."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "จาก 6 directory มี ข้อมูล dir ละ 10000 ซึ่งเป็นข้อมูลประเภท dictionary จึงได้สร้าง list ไว้ใช้เก็บข้อมูล 4 list คือ list ไว้สำหรับเก็บ training data, testing data, label of training data, label of testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = [r\"C:\\Users\\dell\\Desktop\\module8&9\\AI\\Lab03\\cifar-10-batches-py\\data_batch_1\",\n",
    "        r\"C:\\Users\\dell\\Desktop\\module8&9\\AI\\Lab03\\cifar-10-batches-py\\data_batch_2\",\n",
    "        r\"C:\\Users\\dell\\Desktop\\module8&9\\AI\\Lab03\\cifar-10-batches-py\\data_batch_3\",\n",
    "        r\"C:\\Users\\dell\\Desktop\\module8&9\\AI\\Lab03\\cifar-10-batches-py\\data_batch_4\",\n",
    "        r\"C:\\Users\\dell\\Desktop\\module8&9\\AI\\Lab03\\cifar-10-batches-py\\data_batch_5\",\n",
    "        r\"C:\\Users\\dell\\Desktop\\module8&9\\AI\\Lab03\\cifar-10-batches-py\\test_batch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = []\n",
    "label_train = []\n",
    "data_test = []\n",
    "label_test =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(directory)):\n",
    "    if i != len(directory)-1:\n",
    "        raw_data = unpickle(directory[i])\n",
    "        for ind in range(len(raw_data[b'data'])):\n",
    "            data_train.append(raw_data[b'data'][ind])\n",
    "            label_train.append(raw_data[b'labels'][ind])\n",
    "    else:\n",
    "        raw_data = unpickle(directory[i])\n",
    "        for ind in range(len(raw_data[b'data'])):\n",
    "            data_test.append(raw_data[b'data'][ind])\n",
    "            label_test.append(raw_data[b'labels'][ind])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classify Dogs v.s. Cats\n",
    "\n",
    "Let’s start simple by creating logistic regression model to classify images. We will select only two classes of images for this exercise.\n",
    "\n",
    "1. From 50,000 train images and 10,000 test images, we want to reduce the data size. Write code to filter only dog images (label = 3) and cat images (label = 5).\n",
    "2. Create a logistic regression model to classify cats and dogs. Report your accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce data size\n",
    "อาศัย loop เพื่อ select data ที่มี label = 3 or 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_data_train = []\n",
    "fil_data_test =[]\n",
    "fil_label_train = []\n",
    "fil_label_test = []\n",
    "\n",
    "for i in range(len(data_train)):\n",
    "    if label_train[i] == 3:\n",
    "        fil_data_train.append(data_train[i])\n",
    "        fil_label_train.append(3)\n",
    "    elif label_train[i] == 5:\n",
    "        fil_data_train.append(data_train[i])\n",
    "        fil_label_train.append(5)\n",
    "\n",
    "for i in range(len(data_test)):\n",
    "    if label_test[i] == 3:\n",
    "        fil_data_test.append(data_test[i])\n",
    "        fil_label_test.append(3)\n",
    "    elif label_test[i] == 5:\n",
    "        fil_data_test.append(data_test[i])\n",
    "        fil_label_test.append(5)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Logistic Regression Model \n",
    "ได้ accuracy = 53.5 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logregr.fit(fil_data_train,fil_label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Logistic Regression model--------------------\n",
      "\n",
      "           The accuracy is 0.5325 or 53.25%\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "acc = logregr.score(fil_data_test,fil_label_test)\n",
    "print('---------------Logistic Regression model--------------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. The Real Challenge\n",
    "\n",
    "The majority of your score for this lab will come from this real challenge. You are going to construct a neural network model to classify 10 classes of images from CIFAR-10 dataset. You will get half the credits for this one if you complete the assignment, and will get another half if you can exceed the target accuracy of 75%. (You may use any combination of sklearn, opencv, or tensorflow to do this exercise).\n",
    "\n",
    "Design at least 3 variants of neural network models. Each model should have different architectures. (Do not vary just a few parameters, the architecture of the network must change in each model). In your notebook, explain your experiments in details and display the accuracy score for each experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. MLP Classifier    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1st Experiment process with preprocessing data\n",
    "    MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(50, 50, 50, 50, 50), learning_rate='constant',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "    accuracy = 0.3718\n",
    "---------------------------------------------------------------------------\n",
    "2nd Experiment process with preprocessing data\n",
    "    MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(100, 100, 100, 100, 100),\n",
    "       learning_rate='constant', learning_rate_init=0.001, max_iter=500,\n",
    "       momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
    "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
    "       validation_fraction=0.1, verbose=True, warm_start=True)\n",
    "    accuracy = 0.422\n",
    "---------------------------------------------------------------------------\n",
    "3rd Experiment process with preprocessing data\n",
    "    MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(500, 400, 300, 100, 100),\n",
    "       learning_rate='adaptive', learning_rate_init=0.001, max_iter=500,\n",
    "       momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
    "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
    "       validation_fraction=0.1, verbose=True, warm_start=True)\n",
    "    accuracy = 0.4637\n",
    "---------------------------------------------------------------------------\n",
    "4th Experiment process with preprocessing data\n",
    "    MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(1000, 500, 400), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "    accuracy = 0.4976\n",
    "---------------------------------------------------------------------------\n",
    "5th Experiment *****process with unpreprocessing data\n",
    "    MLP = MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(1000, 500, 400), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "    accuracy = 0.137\n",
    "---------------------------------------------------------------------------\n",
    "6th Experiment ******process with unpreprocessing data\n",
    "    MLP = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(100,100,100,100,100,100,100,100,100,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)    \n",
    "    accuracy = 0.4434\n",
    "---------------------------------------------------------------------------\n",
    "7th Experiment process with preprocessing data\n",
    "    MLP = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(100,100,100,100,100,100,100,100,100,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)  \n",
    "    accuracy = 0.5108\n",
    "---------------------------------------------------------------------------\n",
    "8th Experiment process with preprocessing data\n",
    "    MLP = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(500,400,400,300,300,100,100,100,100,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)  \n",
    "    accuracy = 0.5409\n",
    "---------------------------------------------------------------------------\n",
    "9th Experiment process with preprocessing data\n",
    "    MLP = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(1000,900,800,700,600,500,400,300,200,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)    \n",
    "    accuracy = 0.5378\n",
    "---------------------------------------------------------------------------\n",
    "10th Experiment process with preprocessing data\n",
    "    MLP = MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(1000,900,800,700,600,500,400,300,200,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)  \n",
    "    accuracy = 0.3678\n",
    "---------------------------------------------------------------------------\n",
    "11th Experiment process with preprocessing data\n",
    "    MLP = MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(1000,900,800,700,600,500,400,300,200,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True) \n",
    "    accuracy = 0.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()  \n",
    "scaler.fit(data_train)\n",
    "x_train = scaler.transform(data_train)\n",
    "x_test = scaler.transform(data_test)\n",
    "y_train = label_train\n",
    "y_test = label_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.22528966\n",
      "Validation score: 0.185800\n",
      "Iteration 2, loss = 2.04818440\n",
      "Validation score: 0.192800\n",
      "Iteration 3, loss = 2.01528579\n",
      "Validation score: 0.204800\n",
      "Iteration 4, loss = 1.99214377\n",
      "Validation score: 0.222800\n",
      "Iteration 5, loss = 1.97523115\n",
      "Validation score: 0.211400\n",
      "Iteration 6, loss = 1.95733482\n",
      "Validation score: 0.230000\n",
      "Iteration 7, loss = 1.93876435\n",
      "Validation score: 0.238600\n",
      "Iteration 8, loss = 1.92170168\n",
      "Validation score: 0.237000\n",
      "Iteration 9, loss = 1.90699760\n",
      "Validation score: 0.249400\n",
      "Iteration 10, loss = 1.88843833\n",
      "Validation score: 0.272200\n",
      "Iteration 11, loss = 1.85692325\n",
      "Validation score: 0.302200\n",
      "Iteration 12, loss = 1.81587432\n",
      "Validation score: 0.296000\n",
      "Iteration 13, loss = 1.78822993\n",
      "Validation score: 0.295400\n",
      "Iteration 14, loss = 1.76797491\n",
      "Validation score: 0.304800\n",
      "Iteration 15, loss = 1.75132663\n",
      "Validation score: 0.308000\n",
      "Iteration 16, loss = 1.73504445\n",
      "Validation score: 0.317600\n",
      "Iteration 17, loss = 1.72146247\n",
      "Validation score: 0.317200\n",
      "Iteration 18, loss = 1.70636475\n",
      "Validation score: 0.328600\n",
      "Iteration 19, loss = 1.69112348\n",
      "Validation score: 0.323600\n",
      "Iteration 20, loss = 1.67491058\n",
      "Validation score: 0.329800\n",
      "Iteration 21, loss = 1.65928564\n",
      "Validation score: 0.332400\n",
      "Iteration 22, loss = 1.64651128\n",
      "Validation score: 0.333400\n",
      "Iteration 23, loss = 1.63293108\n",
      "Validation score: 0.340000\n",
      "Iteration 24, loss = 1.61832550\n",
      "Validation score: 0.346200\n",
      "Iteration 25, loss = 1.60028884\n",
      "Validation score: 0.348200\n",
      "Iteration 26, loss = 1.58746013\n",
      "Validation score: 0.348200\n",
      "Iteration 27, loss = 1.57339816\n",
      "Validation score: 0.349000\n",
      "Iteration 28, loss = 1.55848785\n",
      "Validation score: 0.355000\n",
      "Iteration 29, loss = 1.54443941\n",
      "Validation score: 0.354800\n",
      "Iteration 30, loss = 1.53136336\n",
      "Validation score: 0.360600\n",
      "Iteration 31, loss = 1.52208363\n",
      "Validation score: 0.364400\n",
      "Iteration 32, loss = 1.50302751\n",
      "Validation score: 0.365600\n",
      "Iteration 33, loss = 1.49370847\n",
      "Validation score: 0.368800\n",
      "Iteration 34, loss = 1.47918908\n",
      "Validation score: 0.367400\n",
      "Iteration 35, loss = 1.46968031\n",
      "Validation score: 0.370200\n",
      "Iteration 36, loss = 1.45653573\n",
      "Validation score: 0.374000\n",
      "Iteration 37, loss = 1.44752093\n",
      "Validation score: 0.365400\n",
      "Iteration 38, loss = 1.43582211\n",
      "Validation score: 0.373600\n",
      "Iteration 39, loss = 1.42750397\n",
      "Validation score: 0.373200\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "---------------1st MLP Classifier model--------------------\n",
      "\n",
      "------------Process with preprocessing data----------------\n",
      "\n",
      "           The accuracy is 0.3718 or 37.18%\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(50, 50, 50, 50, 50), learning_rate='constant',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "MLP.fit(x_train,y_train)\n",
    "acc = MLP.score(x_test,y_test)\n",
    "print('---------------1st MLP Classifier model--------------------\\n')\n",
    "print('------------Process with preprocessing data----------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.15456693\n",
      "Validation score: 0.190200\n",
      "Iteration 2, loss = 2.02686805\n",
      "Validation score: 0.211400\n",
      "Iteration 3, loss = 1.99216041\n",
      "Validation score: 0.203600\n",
      "Iteration 4, loss = 1.96443496\n",
      "Validation score: 0.222800\n",
      "Iteration 5, loss = 1.93909555\n",
      "Validation score: 0.219000\n",
      "Iteration 6, loss = 1.91196981\n",
      "Validation score: 0.239800\n",
      "Iteration 7, loss = 1.87619862\n",
      "Validation score: 0.267000\n",
      "Iteration 8, loss = 1.80776114\n",
      "Validation score: 0.307000\n",
      "Iteration 9, loss = 1.74241435\n",
      "Validation score: 0.330400\n",
      "Iteration 10, loss = 1.70395315\n",
      "Validation score: 0.349800\n",
      "Iteration 11, loss = 1.67125003\n",
      "Validation score: 0.362800\n",
      "Iteration 12, loss = 1.63488125\n",
      "Validation score: 0.372200\n",
      "Iteration 13, loss = 1.60394036\n",
      "Validation score: 0.363600\n",
      "Iteration 14, loss = 1.57814230\n",
      "Validation score: 0.380000\n",
      "Iteration 15, loss = 1.54870427\n",
      "Validation score: 0.383400\n",
      "Iteration 16, loss = 1.52320927\n",
      "Validation score: 0.389800\n",
      "Iteration 17, loss = 1.49373081\n",
      "Validation score: 0.395000\n",
      "Iteration 18, loss = 1.46875613\n",
      "Validation score: 0.393800\n",
      "Iteration 19, loss = 1.43655718\n",
      "Validation score: 0.404000\n",
      "Iteration 20, loss = 1.41656561\n",
      "Validation score: 0.400000\n",
      "Iteration 21, loss = 1.38578918\n",
      "Validation score: 0.400800\n",
      "Iteration 22, loss = 1.36432092\n",
      "Validation score: 0.407400\n",
      "Iteration 23, loss = 1.34521627\n",
      "Validation score: 0.404600\n",
      "Iteration 24, loss = 1.32180484\n",
      "Validation score: 0.412400\n",
      "Iteration 25, loss = 1.30045529\n",
      "Validation score: 0.415800\n",
      "Iteration 26, loss = 1.28296756\n",
      "Validation score: 0.415800\n",
      "Iteration 27, loss = 1.25923137\n",
      "Validation score: 0.411000\n",
      "Iteration 28, loss = 1.24256792\n",
      "Validation score: 0.418000\n",
      "Iteration 29, loss = 1.22737721\n",
      "Validation score: 0.420200\n",
      "Iteration 30, loss = 1.20861236\n",
      "Validation score: 0.411600\n",
      "Iteration 31, loss = 1.19281382\n",
      "Validation score: 0.416400\n",
      "Iteration 32, loss = 1.18103914\n",
      "Validation score: 0.411600\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "---------------2nd MLP Classifier model--------------------\n",
      "\n",
      "------------Process with preprocessing data----------------\n",
      "\n",
      "           The accuracy is 0.422 or 42.199999999999996%\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(100, 100, 100, 100, 100),\n",
    "       learning_rate='constant', learning_rate_init=0.001, max_iter=500,\n",
    "       momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
    "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
    "       validation_fraction=0.1, verbose=True, warm_start=True)\n",
    "MLP.fit(x_train,y_train)\n",
    "acc = MLP.score(x_test,y_test)\n",
    "print('---------------2nd MLP Classifier model--------------------\\n')\n",
    "print('------------Process with preprocessing data----------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.10604733\n",
      "Validation score: 0.202000\n",
      "Iteration 2, loss = 1.96744914\n",
      "Validation score: 0.277000\n",
      "Iteration 3, loss = 1.81963945\n",
      "Validation score: 0.335600\n",
      "Iteration 4, loss = 1.70779112\n",
      "Validation score: 0.382000\n",
      "Iteration 5, loss = 1.60825782\n",
      "Validation score: 0.423200\n",
      "Iteration 6, loss = 1.53457109\n",
      "Validation score: 0.434000\n",
      "Iteration 7, loss = 1.47103216\n",
      "Validation score: 0.448600\n",
      "Iteration 8, loss = 1.41457515\n",
      "Validation score: 0.455400\n",
      "Iteration 9, loss = 1.37016463\n",
      "Validation score: 0.444000\n",
      "Iteration 10, loss = 1.31575987\n",
      "Validation score: 0.452400\n",
      "Iteration 11, loss = 1.27075653\n",
      "Validation score: 0.458000\n",
      "Iteration 12, loss = 1.23139332\n",
      "Validation score: 0.468200\n",
      "Iteration 13, loss = 1.18179987\n",
      "Validation score: 0.461600\n",
      "Iteration 14, loss = 1.14386309\n",
      "Validation score: 0.467800\n",
      "Iteration 15, loss = 1.08775994\n",
      "Validation score: 0.464800\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "---------------3rd MLP Classifier model--------------------\n",
      "\n",
      "------------Process with preprocessing data----------------\n",
      "\n",
      "           The accuracy is 0.4637 or 46.37%\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(500, 400, 300, 100, 100),\n",
    "       learning_rate='adaptive', learning_rate_init=0.001, max_iter=500,\n",
    "       momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
    "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
    "       validation_fraction=0.1, verbose=True, warm_start=True)\n",
    "MLP.fit(x_train,y_train)\n",
    "acc = MLP.score(x_test,y_test)\n",
    "print('---------------3rd MLP Classifier model--------------------\\n')\n",
    "print('------------Process with preprocessing data----------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.81586586\n",
      "Validation score: 0.406600\n",
      "Iteration 2, loss = 1.57970449\n",
      "Validation score: 0.444400\n",
      "Iteration 3, loss = 1.47506294\n",
      "Validation score: 0.465200\n",
      "Iteration 4, loss = 1.38908820\n",
      "Validation score: 0.472400\n",
      "Iteration 5, loss = 1.32161253\n",
      "Validation score: 0.484800\n",
      "Iteration 6, loss = 1.25433929\n",
      "Validation score: 0.498400\n",
      "Iteration 7, loss = 1.19023244\n",
      "Validation score: 0.499200\n",
      "Iteration 8, loss = 1.13519231\n",
      "Validation score: 0.494800\n",
      "Iteration 9, loss = 1.07372844\n",
      "Validation score: 0.494400\n",
      "Iteration 10, loss = 1.01196842\n",
      "Validation score: 0.504000\n",
      "Iteration 11, loss = 0.95024389\n",
      "Validation score: 0.509600\n",
      "Iteration 12, loss = 0.88645396\n",
      "Validation score: 0.496600\n",
      "Iteration 13, loss = 0.83951156\n",
      "Validation score: 0.514800\n",
      "Iteration 14, loss = 0.77272687\n",
      "Validation score: 0.504800\n",
      "Iteration 15, loss = 0.72634928\n",
      "Validation score: 0.510600\n",
      "Iteration 16, loss = 0.66815233\n",
      "Validation score: 0.500400\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "---------------4th MLP Classifier model--------------------\n",
      "\n",
      "------------Process with preprocessing data----------------\n",
      "\n",
      "           The accuracy is 0.4976 or 49.76%\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(1000, 500, 400), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "MLP.fit(x_train,y_train)\n",
    "acc = MLP.score(x_test,y_test)\n",
    "print('---------------4th MLP Classifier model--------------------\\n')\n",
    "print('------------Process with preprocessing data----------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.31127638\n",
      "Validation score: 0.095800\n",
      "Iteration 2, loss = 2.28365547\n",
      "Validation score: 0.122400\n",
      "Iteration 3, loss = 2.26960654\n",
      "Validation score: 0.137200\n",
      "Iteration 4, loss = 2.23806878\n",
      "Validation score: 0.146200\n",
      "Iteration 5, loss = 2.30855971\n",
      "Validation score: 0.098600\n",
      "Iteration 6, loss = 2.30452269\n",
      "Validation score: 0.098400\n",
      "Iteration 7, loss = 2.30286019\n",
      "Validation score: 0.096400\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "---------------5th MLP Classifier model--------------------\n",
      "\n",
      "-----------Process with unpreprocessing data---------------\n",
      "\n",
      "           The accuracy is 0.137 or 13.700000000000001%\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(1000, 500, 400), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "MLP.fit(data_train,label_train)\n",
    "acc = MLP.score(data_test,label_test)\n",
    "print('---------------5th MLP Classifier model--------------------\\n')\n",
    "print('-----------Process with unpreprocessing data---------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.66754084\n",
      "Validation score: 0.297000\n",
      "Iteration 2, loss = 1.85065128\n",
      "Validation score: 0.354400\n",
      "Iteration 3, loss = 1.77459145\n",
      "Validation score: 0.366000\n",
      "Iteration 4, loss = 1.72842975\n",
      "Validation score: 0.355000\n",
      "Iteration 5, loss = 1.69669273\n",
      "Validation score: 0.405800\n",
      "Iteration 6, loss = 1.64747330\n",
      "Validation score: 0.414600\n",
      "Iteration 7, loss = 1.63327315\n",
      "Validation score: 0.401800\n",
      "Iteration 8, loss = 1.61226285\n",
      "Validation score: 0.415600\n",
      "Iteration 9, loss = 1.60499469\n",
      "Validation score: 0.416200\n",
      "Iteration 10, loss = 1.58060749\n",
      "Validation score: 0.431200\n",
      "Iteration 11, loss = 1.56423379\n",
      "Validation score: 0.415800\n",
      "Iteration 12, loss = 1.54568369\n",
      "Validation score: 0.438600\n",
      "Iteration 13, loss = 1.53886377\n",
      "Validation score: 0.445400\n",
      "Iteration 14, loss = 1.52537428\n",
      "Validation score: 0.442400\n",
      "Iteration 15, loss = 1.51633013\n",
      "Validation score: 0.440000\n",
      "Iteration 16, loss = 1.52015414\n",
      "Validation score: 0.433400\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "---------------6th MLP Classifier model--------------------\n",
      "\n",
      "-----------Process with unpreprocessing data---------------\n",
      "\n",
      "           The accuracy is 0.4434 or 44.34%\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(100,100,100,100,100,100,100,100,100,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "MLP.fit(data_train,label_train)\n",
    "acc = MLP.score(data_test,label_test)\n",
    "print('---------------6th MLP Classifier model--------------------\\n')\n",
    "print('-----------Process with unpreprocessing data---------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.79312558\n",
      "Validation score: 0.397800\n",
      "Iteration 2, loss = 1.55285671\n",
      "Validation score: 0.437400\n",
      "Iteration 3, loss = 1.44625073\n",
      "Validation score: 0.453800\n",
      "Iteration 4, loss = 1.37499698\n",
      "Validation score: 0.461200\n",
      "Iteration 5, loss = 1.31543335\n",
      "Validation score: 0.475400\n",
      "Iteration 6, loss = 1.26160755\n",
      "Validation score: 0.468800\n",
      "Iteration 7, loss = 1.21996080\n",
      "Validation score: 0.483800\n",
      "Iteration 8, loss = 1.17214318\n",
      "Validation score: 0.490600\n",
      "Iteration 9, loss = 1.13189771\n",
      "Validation score: 0.491200\n",
      "Iteration 10, loss = 1.09873682\n",
      "Validation score: 0.498000\n",
      "Iteration 11, loss = 1.05323321\n",
      "Validation score: 0.486600\n",
      "Iteration 12, loss = 1.02254937\n",
      "Validation score: 0.498800\n",
      "Iteration 13, loss = 0.99073988\n",
      "Validation score: 0.502000\n",
      "Iteration 14, loss = 0.96277519\n",
      "Validation score: 0.486400\n",
      "Iteration 15, loss = 0.92139270\n",
      "Validation score: 0.498800\n",
      "Iteration 16, loss = 0.90447135\n",
      "Validation score: 0.498000\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "---------------7th MLP Classifier model--------------------\n",
      "\n",
      "-----------Process with preprocessing data---------------\n",
      "\n",
      "           The accuracy is 0.5108 or 51.080000000000005%\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(100,100,100,100,100,100,100,100,100,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "MLP.fit(x_train,y_train)\n",
    "acc = MLP.score(x_test,y_test)\n",
    "print('---------------7th MLP Classifier model--------------------\\n')\n",
    "print('-----------Process with preprocessing data---------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.77874073\n",
      "Validation score: 0.436400\n",
      "Iteration 2, loss = 1.53629391\n",
      "Validation score: 0.457400\n",
      "Iteration 3, loss = 1.41672509\n",
      "Validation score: 0.490400\n",
      "Iteration 4, loss = 1.31534418\n",
      "Validation score: 0.512200\n",
      "Iteration 5, loss = 1.23427576\n",
      "Validation score: 0.518800\n",
      "Iteration 6, loss = 1.15868143\n",
      "Validation score: 0.513000\n",
      "Iteration 7, loss = 1.08329536\n",
      "Validation score: 0.539400\n",
      "Iteration 8, loss = 1.00615204\n",
      "Validation score: 0.534400\n",
      "Iteration 9, loss = 0.93310391\n",
      "Validation score: 0.531600\n",
      "Iteration 10, loss = 0.87589228\n",
      "Validation score: 0.550800\n",
      "Iteration 11, loss = 0.81383054\n",
      "Validation score: 0.534600\n",
      "Iteration 12, loss = 0.74110071\n",
      "Validation score: 0.543200\n",
      "Iteration 13, loss = 0.68592842\n",
      "Validation score: 0.529600\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "---------------8th MLP Classifier model--------------------\n",
      "\n",
      "-----------Process with preprocessing data---------------\n",
      "\n",
      "           The accuracy is 0.5409 or 54.09%\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(500,400,400,300,300,100,100,100,100,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "MLP.fit(x_train,y_train)\n",
    "acc = MLP.score(x_test,y_test)\n",
    "print('---------------8th MLP Classifier model--------------------\\n')\n",
    "print('-----------Process with preprocessing data---------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.79064328\n",
      "Validation score: 0.395400\n",
      "Iteration 2, loss = 1.55611775\n",
      "Validation score: 0.433800\n",
      "Iteration 3, loss = 1.44342729\n",
      "Validation score: 0.478600\n",
      "Iteration 4, loss = 1.35078849\n",
      "Validation score: 0.488200\n",
      "Iteration 5, loss = 1.26957589\n",
      "Validation score: 0.494000\n",
      "Iteration 6, loss = 1.19471808\n",
      "Validation score: 0.507000\n",
      "Iteration 7, loss = 1.12021668\n",
      "Validation score: 0.516800\n",
      "Iteration 8, loss = 1.04362510\n",
      "Validation score: 0.511800\n",
      "Iteration 9, loss = 0.98441128\n",
      "Validation score: 0.522400\n",
      "Iteration 10, loss = 0.91210777\n",
      "Validation score: 0.529600\n",
      "Iteration 11, loss = 0.83622486\n",
      "Validation score: 0.527600\n",
      "Iteration 12, loss = 0.78213183\n",
      "Validation score: 0.533000\n",
      "Iteration 13, loss = 0.70677238\n",
      "Validation score: 0.532000\n",
      "Iteration 14, loss = 0.65296245\n",
      "Validation score: 0.525600\n",
      "Iteration 15, loss = 0.59084766\n",
      "Validation score: 0.523800\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "---------------9th MLP Classifier model--------------------\n",
      "\n",
      "-----------Process with preprocessing data---------------\n",
      "\n",
      "           The accuracy is 0.5378 or 53.779999999999994%\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(1000,900,800,700,600,500,400,300,200,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "MLP.fit(x_train,y_train)\n",
    "acc = MLP.score(x_test,y_test)\n",
    "print('---------------9th MLP Classifier model--------------------\\n')\n",
    "print('-----------Process with preprocessing data---------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.97887843\n",
      "Validation score: 0.308000\n",
      "Iteration 2, loss = 1.87301104\n",
      "Validation score: 0.325000\n",
      "Iteration 3, loss = 1.82311427\n",
      "Validation score: 0.340200\n",
      "Iteration 4, loss = 1.79957459\n",
      "Validation score: 0.353800\n",
      "Iteration 5, loss = 1.80377888\n",
      "Validation score: 0.324200\n",
      "Iteration 6, loss = 1.84983993\n",
      "Validation score: 0.328600\n",
      "Iteration 7, loss = 1.82090762\n",
      "Validation score: 0.322800\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "---------------10th MLP Classifier model--------------------\n",
      "\n",
      "-----------Process with preprocessing data------------------\n",
      "\n",
      "           The accuracy is 0.3678 or 36.78%\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(1000,900,800,700,600,500,400,300,200,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "MLP.fit(x_train,y_train)\n",
    "acc = MLP.score(x_test,y_test)\n",
    "print('---------------10th MLP Classifier model--------------------\\n')\n",
    "print('-----------Process with preprocessing data------------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.30792319\n",
      "Validation score: 0.096600\n",
      "Iteration 2, loss = 2.30564063\n",
      "Validation score: 0.092800\n",
      "Iteration 3, loss = 2.30499634\n",
      "Validation score: 0.103800\n",
      "Iteration 4, loss = 2.30506988\n",
      "Validation score: 0.096600\n",
      "Iteration 5, loss = 2.30450753\n",
      "Validation score: 0.102400\n",
      "Iteration 6, loss = 2.30420944\n",
      "Validation score: 0.108000\n",
      "Iteration 7, loss = 2.30362340\n",
      "Validation score: 0.092800\n",
      "Iteration 8, loss = 2.30336573\n",
      "Validation score: 0.092800\n",
      "Iteration 9, loss = 2.30314584\n",
      "Validation score: 0.103800\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "---------------11th MLP Classifier model--------------------\n",
      "\n",
      "-----------Process with preprocessing data------------------\n",
      "\n",
      "           The accuracy is 0.1 or 10.0%\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(1000,900,800,700,600,500,400,300,200,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "MLP.fit(x_train,y_train)\n",
    "acc = MLP.score(x_test,y_test)\n",
    "print('---------------11th MLP Classifier model--------------------\\n')\n",
    "print('-----------Process with preprocessing data------------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Convolution Neural Network(CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Flatten,Conv2D,BatchNormalization,Dropout,MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x3d_train = np.array(data_train).reshape(np.array(data_train).shape[0],3,32,32)\n",
    "x3d_test = np.array(data_test).reshape(np.array(data_test).shape[0],3,32,32)\n",
    "\n",
    "y_train = to_categorical(label_train,++10)\n",
    "y_test = to_categorical(label_test,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 1240s 25ms/step - loss: 1.5923 - acc: 0.4529 - val_loss: 1.6117 - val_acc: 0.4622\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 1177s 24ms/step - loss: 1.1611 - acc: 0.5926 - val_loss: 1.3985 - val_acc: 0.5372\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 1183s 24ms/step - loss: 0.9683 - acc: 0.6643 - val_loss: 1.1417 - val_acc: 0.6163\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 1165s 23ms/step - loss: 0.7799 - acc: 0.7291 - val_loss: 1.1928 - val_acc: 0.6195\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 1154s 23ms/step - loss: 0.6118 - acc: 0.7883 - val_loss: 1.5194 - val_acc: 0.5885\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 1141s 23ms/step - loss: 0.4714 - acc: 0.8394 - val_loss: 1.5636 - val_acc: 0.6117\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 1137s 23ms/step - loss: 0.3648 - acc: 0.8762 - val_loss: 1.4994 - val_acc: 0.6267\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 1149s 23ms/step - loss: 0.2959 - acc: 0.9035 - val_loss: 1.6680 - val_acc: 0.6299\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 1157s 23ms/step - loss: 0.2371 - acc: 0.9230 - val_loss: 1.9181 - val_acc: 0.6199\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 1160s 23ms/step - loss: 0.1988 - acc: 0.9360 - val_loss: 2.1887 - val_acc: 0.5937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x272b03976a0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model1 = Sequential()\n",
    "\n",
    "Model1.add(Conv2D(filters=32,kernel_size=(5,5),padding='same',data_format='channels_first',activation='relu',use_bias=False,input_shape=(3,32,32)))\n",
    "Model1.add(BatchNormalization(axis=1))\n",
    "Model1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "Model1.add(Flatten())\n",
    "Model1.add(Dense(1000,activation='relu'))\n",
    "Model1.add(Dense(500,activation='relu'))\n",
    "Model1.add(Dense(10,activation='softmax'))\n",
    "\n",
    "Model1.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "Model1.fit(x3d_train,y_train, validation_data=(x3d_test,y_test),epochs = 10,batch_size = 8)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Architecture: \n",
    "Conv2D 32 filter(5,5) --> BatchNormalize --> Maxpooling --> Flatten --> Dense(1000) --> Dense(500) --> Dense(10)\n",
    "Accuracy = 0.5937 = 59.37%\n",
    "\n",
    "Result\n",
    "Train on 50000 samples, validate on 10000 samples\n",
    "Epoch 1/10\n",
    "50000/50000 [==============================] - 1240s 25ms/step - loss: 1.5923 - acc: 0.4529 - val_loss: 1.6117 - val_acc: 0.4622\n",
    "Epoch 2/10\n",
    "50000/50000 [==============================] - 1177s 24ms/step - loss: 1.1611 - acc: 0.5926 - val_loss: 1.3985 - val_acc: 0.5372\n",
    "Epoch 3/10\n",
    "50000/50000 [==============================] - 1183s 24ms/step - loss: 0.9683 - acc: 0.6643 - val_loss: 1.1417 - val_acc: 0.6163\n",
    "Epoch 4/10\n",
    "50000/50000 [==============================] - 1165s 23ms/step - loss: 0.7799 - acc: 0.7291 - val_loss: 1.1928 - val_acc: 0.6195\n",
    "Epoch 5/10\n",
    "50000/50000 [==============================] - 1154s 23ms/step - loss: 0.6118 - acc: 0.7883 - val_loss: 1.5194 - val_acc: 0.5885\n",
    "Epoch 6/10\n",
    "50000/50000 [==============================] - 1141s 23ms/step - loss: 0.4714 - acc: 0.8394 - val_loss: 1.5636 - val_acc: 0.6117\n",
    "Epoch 7/10\n",
    "50000/50000 [==============================] - 1137s 23ms/step - loss: 0.3648 - acc: 0.8762 - val_loss: 1.4994 - val_acc: 0.6267\n",
    "Epoch 8/10\n",
    "50000/50000 [==============================] - 1149s 23ms/step - loss: 0.2959 - acc: 0.9035 - val_loss: 1.6680 - val_acc: 0.6299\n",
    "Epoch 9/10\n",
    "50000/50000 [==============================] - 1157s 23ms/step - loss: 0.2371 - acc: 0.9230 - val_loss: 1.9181 - val_acc: 0.6199\n",
    "Epoch 10/10\n",
    "50000/50000 [==============================] - 1160s 23ms/step - loss: 0.1988 - acc: 0.9360 - val_loss: 2.1887 - val_acc: 0.5937"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากผลลัพธ์ พบว่า model มีความ overfit สูงมาก ทั้งนี้คิดว่าเป็นเพราะมี fully connetor ซ้อนกัน 3 ชั้น และมีจำนวนว node เยอะเกินไป จึงได้ปรับเปลี่ยนเป็น model3 โดย ได้ทำการลด node ของ fully contected layer ลง และทำการเพิ่ม convolution layer เนื่องจากคิดว่ารูปมีทั้งหมด 10 class การที่มี conv เยอะๆจะช่วยให้สามารถแยก class ได้เยอะ และได้ทำการเพิ่ม drop out เพื่อป้องกันการ overfit ของ model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 1634s 33ms/step - loss: 1.6541 - acc: 0.3958 - val_loss: 3.6330 - val_acc: 0.3291\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 1624s 32ms/step - loss: 1.3479 - acc: 0.5103 - val_loss: 1.3301 - val_acc: 0.5162\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 1613s 32ms/step - loss: 1.1849 - acc: 0.5745 - val_loss: 1.2925 - val_acc: 0.5363\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 1618s 32ms/step - loss: 1.0619 - acc: 0.6226 - val_loss: 1.0897 - val_acc: 0.6157\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 1618s 32ms/step - loss: 0.9673 - acc: 0.6572 - val_loss: 1.1977 - val_acc: 0.5849\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 1607s 32ms/step - loss: 0.8937 - acc: 0.6836 - val_loss: 0.9780 - val_acc: 0.6571\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 1612s 32ms/step - loss: 0.8355 - acc: 0.7046 - val_loss: 0.9990 - val_acc: 0.6509\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 1717s 34ms/step - loss: 0.7818 - acc: 0.7253 - val_loss: 1.2301 - val_acc: 0.5933\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 1716s 34ms/step - loss: 0.7419 - acc: 0.7370 - val_loss: 0.9917 - val_acc: 0.6647\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 1732s 35ms/step - loss: 0.6985 - acc: 0.7536 - val_loss: 0.8762 - val_acc: 0.7010\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 1745s 35ms/step - loss: 0.6688 - acc: 0.7630 - val_loss: 0.8428 - val_acc: 0.7144\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 1795s 36ms/step - loss: 0.6377 - acc: 0.7751 - val_loss: 0.8989 - val_acc: 0.6985\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 1741s 35ms/step - loss: 0.6089 - acc: 0.7855 - val_loss: 0.8314 - val_acc: 0.7143\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 1736s 35ms/step - loss: 0.5874 - acc: 0.7934 - val_loss: 0.8765 - val_acc: 0.7082\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 1747s 35ms/step - loss: 0.5707 - acc: 0.7985 - val_loss: 0.9762 - val_acc: 0.6858\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 1755s 35ms/step - loss: 0.5484 - acc: 0.8066 - val_loss: 0.8010 - val_acc: 0.7324\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 1714s 34ms/step - loss: 0.5197 - acc: 0.8155 - val_loss: 1.6506 - val_acc: 0.6557\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 1746s 35ms/step - loss: 0.5157 - acc: 0.8178 - val_loss: 0.9260 - val_acc: 0.7015\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 1743s 35ms/step - loss: 0.4871 - acc: 0.8286 - val_loss: 0.8662 - val_acc: 0.7294\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 1740s 35ms/step - loss: 0.4703 - acc: 0.8344 - val_loss: 0.7881 - val_acc: 0.7416\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 1740s 35ms/step - loss: 0.4628 - acc: 0.8357 - val_loss: 0.8728 - val_acc: 0.7270\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 1724s 34ms/step - loss: 0.4443 - acc: 0.8414 - val_loss: 0.8528 - val_acc: 0.7329\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 1611s 32ms/step - loss: 0.4321 - acc: 0.8483 - val_loss: 0.9181 - val_acc: 0.7144\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 2055s 41ms/step - loss: 0.4311 - acc: 0.8470 - val_loss: 0.8615 - val_acc: 0.7288\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 1767s 35ms/step - loss: 0.4050 - acc: 0.8549 - val_loss: 0.9034 - val_acc: 0.7266\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 1737s 35ms/step - loss: 0.3953 - acc: 0.8593 - val_loss: 0.8346 - val_acc: 0.7486\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 1733s 35ms/step - loss: 0.3840 - acc: 0.8632 - val_loss: 0.8770 - val_acc: 0.7281\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 1730s 35ms/step - loss: 0.3708 - acc: 0.8685 - val_loss: 0.8825 - val_acc: 0.7414\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 1736s 35ms/step - loss: 0.3661 - acc: 0.8707 - val_loss: 0.8783 - val_acc: 0.7263\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 1742s 35ms/step - loss: 0.3560 - acc: 0.8733 - val_loss: 0.9214 - val_acc: 0.7308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2730e7234a8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model3 = Sequential()\n",
    "\n",
    "Model3.add(Conv2D(filters=128,kernel_size=(8,8),padding='same',data_format='channels_first',activation='relu',use_bias=False,input_shape=(3,32,32)))\n",
    "Model3.add(BatchNormalization(axis=1))\n",
    "Model3.add(Conv2D(filters=64,kernel_size=(4,4),padding='same',data_format='channels_first',activation='relu',use_bias=False,input_shape=(3,32,32)))\n",
    "Model3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "Model3.add(Conv2D(filters=32,kernel_size=(4,4),padding='same',data_format='channels_first',activation='relu',use_bias=False,input_shape=(3,32,32)))\n",
    "Model3.add(Conv2D(filters=32,kernel_size=(2,2),padding='same',data_format='channels_first',activation='relu',use_bias=False,input_shape=(3,32,32)))\n",
    "Model3.add(Conv2D(filters=16,kernel_size=(2,2),padding='same',data_format='channels_first',activation='relu',use_bias=False,input_shape=(3,32,32)))\n",
    "Model3.add(BatchNormalization(axis=1))\n",
    "Model3.add(Dropout(0.5))\n",
    "\n",
    "Model3.add(Flatten())\n",
    "Model3.add(Dense(60,activation='relu'))\n",
    "Model3.add(Dense(30,activation='relu'))\n",
    "Model3.add(Dense(10,activation='softmax'))\n",
    "\n",
    "Model3.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "Model3.fit(x3d_train,y_train, validation_data=(x3d_test,y_test),epochs = 30,batch_size = 64)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Architecture:\n",
    "Conv2D 128 filter(8,8) --> BatchNormalize --> Conv2D 64 filter(4,4) --> MaxPooling(2,2) --> Conv2D 32 filter(4,4) --> Conv2D 32 filter(2,2) --> Conv2D 16 filter(2,2) --> BatchNormalize --> Dropout(0.5) --> Flatten --> Dense 60 --> Dense 30 --> Dense 10\n",
    "Accuracy = 0.7308 = 73.08%\n",
    "\n",
    "\n",
    "Result\n",
    "Train on 50000 samples, validate on 10000 samples\n",
    "Epoch 1/30\n",
    "50000/50000 [==============================] - 1634s 33ms/step - loss: 1.6541 - acc: 0.3958 - val_loss: 3.6330 - val_acc: 0.3291\n",
    "Epoch 2/30\n",
    "50000/50000 [==============================] - 1624s 32ms/step - loss: 1.3479 - acc: 0.5103 - val_loss: 1.3301 - val_acc: 0.5162\n",
    "Epoch 3/30\n",
    "50000/50000 [==============================] - 1613s 32ms/step - loss: 1.1849 - acc: 0.5745 - val_loss: 1.2925 - val_acc: 0.5363\n",
    "Epoch 4/30\n",
    "50000/50000 [==============================] - 1618s 32ms/step - loss: 1.0619 - acc: 0.6226 - val_loss: 1.0897 - val_acc: 0.6157\n",
    "Epoch 5/30\n",
    "50000/50000 [==============================] - 1618s 32ms/step - loss: 0.9673 - acc: 0.6572 - val_loss: 1.1977 - val_acc: 0.5849\n",
    "Epoch 6/30\n",
    "50000/50000 [==============================] - 1607s 32ms/step - loss: 0.8937 - acc: 0.6836 - val_loss: 0.9780 - val_acc: 0.6571\n",
    "Epoch 7/30\n",
    "50000/50000 [==============================] - 1612s 32ms/step - loss: 0.8355 - acc: 0.7046 - val_loss: 0.9990 - val_acc: 0.6509\n",
    "Epoch 8/30\n",
    "50000/50000 [==============================] - 1717s 34ms/step - loss: 0.7818 - acc: 0.7253 - val_loss: 1.2301 - val_acc: 0.5933\n",
    "Epoch 9/30\n",
    "50000/50000 [==============================] - 1716s 34ms/step - loss: 0.7419 - acc: 0.7370 - val_loss: 0.9917 - val_acc: 0.6647\n",
    "Epoch 10/30\n",
    "50000/50000 [==============================] - 1732s 35ms/step - loss: 0.6985 - acc: 0.7536 - val_loss: 0.8762 - val_acc: 0.7010\n",
    "Epoch 11/30\n",
    "50000/50000 [==============================] - 1745s 35ms/step - loss: 0.6688 - acc: 0.7630 - val_loss: 0.8428 - val_acc: 0.7144\n",
    "Epoch 12/30\n",
    "50000/50000 [==============================] - 1795s 36ms/step - loss: 0.6377 - acc: 0.7751 - val_loss: 0.8989 - val_acc: 0.6985\n",
    "Epoch 13/30\n",
    "50000/50000 [==============================] - 1741s 35ms/step - loss: 0.6089 - acc: 0.7855 - val_loss: 0.8314 - val_acc: 0.7143\n",
    "Epoch 14/30\n",
    "50000/50000 [==============================] - 1736s 35ms/step - loss: 0.5874 - acc: 0.7934 - val_loss: 0.8765 - val_acc: 0.7082\n",
    "Epoch 15/30\n",
    "50000/50000 [==============================] - 1747s 35ms/step - loss: 0.5707 - acc: 0.7985 - val_loss: 0.9762 - val_acc: 0.6858\n",
    "Epoch 16/30\n",
    "50000/50000 [==============================] - 1755s 35ms/step - loss: 0.5484 - acc: 0.8066 - val_loss: 0.8010 - val_acc: 0.7324\n",
    "Epoch 17/30\n",
    "50000/50000 [==============================] - 1714s 34ms/step - loss: 0.5197 - acc: 0.8155 - val_loss: 1.6506 - val_acc: 0.6557\n",
    "Epoch 18/30\n",
    "50000/50000 [==============================] - 1746s 35ms/step - loss: 0.5157 - acc: 0.8178 - val_loss: 0.9260 - val_acc: 0.7015\n",
    "Epoch 19/30\n",
    "50000/50000 [==============================] - 1743s 35ms/step - loss: 0.4871 - acc: 0.8286 - val_loss: 0.8662 - val_acc: 0.7294\n",
    "Epoch 20/30\n",
    "50000/50000 [==============================] - 1740s 35ms/step - loss: 0.4703 - acc: 0.8344 - val_loss: 0.7881 - val_acc: 0.7416\n",
    "Epoch 21/30\n",
    "50000/50000 [==============================] - 1740s 35ms/step - loss: 0.4628 - acc: 0.8357 - val_loss: 0.8728 - val_acc: 0.7270\n",
    "Epoch 22/30\n",
    "50000/50000 [==============================] - 1724s 34ms/step - loss: 0.4443 - acc: 0.8414 - val_loss: 0.8528 - val_acc: 0.7329\n",
    "Epoch 23/30\n",
    "50000/50000 [==============================] - 1611s 32ms/step - loss: 0.4321 - acc: 0.8483 - val_loss: 0.9181 - val_acc: 0.7144\n",
    "Epoch 24/30\n",
    "50000/50000 [==============================] - 2055s 41ms/step - loss: 0.4311 - acc: 0.8470 - val_loss: 0.8615 - val_acc: 0.7288\n",
    "Epoch 25/30\n",
    "50000/50000 [==============================] - 1767s 35ms/step - loss: 0.4050 - acc: 0.8549 - val_loss: 0.9034 - val_acc: 0.7266\n",
    "Epoch 26/30\n",
    "50000/50000 [==============================] - 1737s 35ms/step - loss: 0.3953 - acc: 0.8593 - val_loss: 0.8346 - val_acc: 0.7486\n",
    "Epoch 27/30\n",
    "50000/50000 [==============================] - 1733s 35ms/step - loss: 0.3840 - acc: 0.8632 - val_loss: 0.8770 - val_acc: 0.7281\n",
    "Epoch 28/30\n",
    "50000/50000 [==============================] - 1730s 35ms/step - loss: 0.3708 - acc: 0.8685 - val_loss: 0.8825 - val_acc: 0.7414\n",
    "Epoch 29/30\n",
    "50000/50000 [==============================] - 1736s 35ms/step - loss: 0.3661 - acc: 0.8707 - val_loss: 0.8783 - val_acc: 0.7263\n",
    "Epoch 30/30\n",
    "50000/50000 [==============================] - 1742s 35ms/step - loss: 0.3560 - acc: 0.8733 - val_loss: 0.9214 - val_acc: 0.7308"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากผลลัพธ์ พบว่า model มี overfit ลดลง แต่ ไม่สามารถทำให้ accuracy สูงเกินกว่า 75% ได้ จึงคิดว่า จะเปลี่ยนตำแหน่งของ BatchNormalize ตัวแรกเพราะคิดว่าเร็วเกินไปที่จะ Normalize ข้อมูล และเพิ่ม Convolution layer เพิ่มอีก 1 เพื่อให้ model มี accuracy สูงขึ้นได้ และลด Dropout ลงเพราะคิดว่ามีผลทำให้ model ได้ทิ้ง feature ที่สำคัญไปทำให้ accuracy ไมาสามารถเพิ่มขึ้นได้\n",
    "จากแนวคิดทั้งหมดจึงได้ model2 ออกมา"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model2 (FINAL MODEL) ACCURACY = 75.17%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 1500s 30ms/step - loss: 1.7190 - acc: 0.3618 - val_loss: 1.7087 - val_acc: 0.4184\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 1491s 30ms/step - loss: 1.3754 - acc: 0.4966 - val_loss: 1.6545 - val_acc: 0.4204\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 1483s 30ms/step - loss: 1.1870 - acc: 0.5737 - val_loss: 1.4854 - val_acc: 0.4950\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 1482s 30ms/step - loss: 1.0339 - acc: 0.6314 - val_loss: 1.0369 - val_acc: 0.6353\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 1505s 30ms/step - loss: 0.9272 - acc: 0.6697 - val_loss: 0.9406 - val_acc: 0.6698\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 1483s 30ms/step - loss: 0.8512 - acc: 0.6995 - val_loss: 1.0637 - val_acc: 0.6409\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 1482s 30ms/step - loss: 0.7946 - acc: 0.7186 - val_loss: 0.8451 - val_acc: 0.7028\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 1481s 30ms/step - loss: 0.7479 - acc: 0.7364 - val_loss: 0.8510 - val_acc: 0.7058\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 1482s 30ms/step - loss: 0.7065 - acc: 0.7489 - val_loss: 0.8792 - val_acc: 0.6932\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 1483s 30ms/step - loss: 0.6760 - acc: 0.7609 - val_loss: 0.8598 - val_acc: 0.7058\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 1483s 30ms/step - loss: 0.6442 - acc: 0.7711 - val_loss: 0.8485 - val_acc: 0.7139\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 1483s 30ms/step - loss: 0.6109 - acc: 0.7830 - val_loss: 0.9642 - val_acc: 0.6800\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 1483s 30ms/step - loss: 0.5864 - acc: 0.7910 - val_loss: 0.9193 - val_acc: 0.6991\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 1438s 29ms/step - loss: 0.5628 - acc: 0.8007 - val_loss: 0.8046 - val_acc: 0.7355\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 1377s 28ms/step - loss: 0.5386 - acc: 0.8088 - val_loss: 0.8892 - val_acc: 0.7091\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 1381s 28ms/step - loss: 0.5174 - acc: 0.8160 - val_loss: 0.8525 - val_acc: 0.7202\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 1379s 28ms/step - loss: 0.4974 - acc: 0.8218 - val_loss: 0.7958 - val_acc: 0.7427\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 1380s 28ms/step - loss: 0.4819 - acc: 0.8287 - val_loss: 0.7817 - val_acc: 0.7417\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 1385s 28ms/step - loss: 0.4561 - acc: 0.8376 - val_loss: 0.8169 - val_acc: 0.7413\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 1384s 28ms/step - loss: 0.4414 - acc: 0.8419 - val_loss: 0.8369 - val_acc: 0.7443\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 1377s 28ms/step - loss: 0.4240 - acc: 0.8489 - val_loss: 0.8434 - val_acc: 0.7311\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 1376s 28ms/step - loss: 0.4102 - acc: 0.8550 - val_loss: 0.8658 - val_acc: 0.7334\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 1430s 29ms/step - loss: 0.3940 - acc: 0.8612 - val_loss: 0.8969 - val_acc: 0.7357\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 1403s 28ms/step - loss: 0.3749 - acc: 0.8650 - val_loss: 0.8846 - val_acc: 0.7356\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 1385s 28ms/step - loss: 0.3688 - acc: 0.8669 - val_loss: 1.0343 - val_acc: 0.7155\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 1382s 28ms/step - loss: 0.3570 - acc: 0.8718 - val_loss: 0.8489 - val_acc: 0.7492\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 1384s 28ms/step - loss: 0.3401 - acc: 0.8774 - val_loss: 0.8902 - val_acc: 0.7419\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 1380s 28ms/step - loss: 0.3309 - acc: 0.8807 - val_loss: 0.9544 - val_acc: 0.7421\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 1389s 28ms/step - loss: 0.3200 - acc: 0.8842 - val_loss: 0.9410 - val_acc: 0.7390\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 1393s 28ms/step - loss: 0.3105 - acc: 0.8879 - val_loss: 0.8948 - val_acc: 0.7517\n",
      "10000/10000 [==============================] - 111s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "Model2 = Sequential()\n",
    "\n",
    "Model2.add(Conv2D(filters=128,kernel_size=(8,8),padding='same',data_format='channels_first',activation='relu',use_bias=False,input_shape=(3,32,32)))\n",
    "Model2.add(Conv2D(filters=64,kernel_size=(4,4),padding='same',data_format='channels_first',activation='relu',use_bias=False,input_shape=(3,32,32)))\n",
    "Model2.add(BatchNormalization(axis=1))\n",
    "Model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "Model2.add(Conv2D(filters=64,kernel_size=(4,4),padding='same',data_format='channels_first',activation='relu',use_bias=False,input_shape=(3,32,32)))\n",
    "Model2.add(Conv2D(filters=32,kernel_size=(4,4),padding='same',data_format='channels_first',activation='relu',use_bias=False,input_shape=(3,32,32)))\n",
    "Model2.add(Conv2D(filters=16,kernel_size=(2,2),padding='same',data_format='channels_first',activation='relu',use_bias=False,input_shape=(3,32,32)))\n",
    "Model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "Model2.add(BatchNormalization(axis=1))\n",
    "Model2.add(Dropout(0.2))\n",
    "\n",
    "Model2.add(Flatten())\n",
    "Model2.add(Dense(20,activation='relu'))\n",
    "Model2.add(Dense(10,activation='softmax'))\n",
    "\n",
    "Model2.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "hist2 = Model2.fit(x3d_train,y_train, validation_data=(x3d_test,y_test),epochs = 30,batch_size = 64)\n",
    "score2 = Model2.evaluate(x3d_test,y_test,batch_size = 32)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Architecture:\n",
    "conv2D 128 filter(8x8) --> conv2D 64 filter(4x4) --> conv2D 32 filter(4,4) --> BatchNormalize --> Maxpooling2D(2,2) --> conv2D 64 filter(4x4) --> conv2D 32 filter(4x4) --> conv2D 16 filter(4x4) --> Maxpooling(2,2) --> Dropout(0.2) --> Flatten --> Dense(20)-->Dense(10) \n",
    "Accuracy = 0.7517 = 75.17%\n",
    "\n",
    "\n",
    "Result\n",
    "Train on 50000 samples, validate on 10000 samples\n",
    "Epoch 1/30\n",
    "50000/50000 [==============================] - 1500s 30ms/step - loss: 1.7190 - acc: 0.3618 - val_loss: 1.7087 - val_acc: 0.4184\n",
    "Epoch 2/30\n",
    "50000/50000 [==============================] - 1491s 30ms/step - loss: 1.3754 - acc: 0.4966 - val_loss: 1.6545 - val_acc: 0.4204\n",
    "Epoch 3/30\n",
    "50000/50000 [==============================] - 1483s 30ms/step - loss: 1.1870 - acc: 0.5737 - val_loss: 1.4854 - val_acc: 0.4950\n",
    "Epoch 4/30\n",
    "50000/50000 [==============================] - 1482s 30ms/step - loss: 1.0339 - acc: 0.6314 - val_loss: 1.0369 - val_acc: 0.6353\n",
    "Epoch 5/30\n",
    "50000/50000 [==============================] - 1505s 30ms/step - loss: 0.9272 - acc: 0.6697 - val_loss: 0.9406 - val_acc: 0.6698\n",
    "Epoch 6/30\n",
    "50000/50000 [==============================] - 1483s 30ms/step - loss: 0.8512 - acc: 0.6995 - val_loss: 1.0637 - val_acc: 0.6409\n",
    "Epoch 7/30\n",
    "50000/50000 [==============================] - 1482s 30ms/step - loss: 0.7946 - acc: 0.7186 - val_loss: 0.8451 - val_acc: 0.7028\n",
    "Epoch 8/30\n",
    "50000/50000 [==============================] - 1481s 30ms/step - loss: 0.7479 - acc: 0.7364 - val_loss: 0.8510 - val_acc: 0.7058\n",
    "Epoch 9/30\n",
    "50000/50000 [==============================] - 1482s 30ms/step - loss: 0.7065 - acc: 0.7489 - val_loss: 0.8792 - val_acc: 0.6932\n",
    "Epoch 10/30\n",
    "50000/50000 [==============================] - 1483s 30ms/step - loss: 0.6760 - acc: 0.7609 - val_loss: 0.8598 - val_acc: 0.7058\n",
    "Epoch 11/30\n",
    "50000/50000 [==============================] - 1483s 30ms/step - loss: 0.6442 - acc: 0.7711 - val_loss: 0.8485 - val_acc: 0.7139\n",
    "Epoch 12/30\n",
    "50000/50000 [==============================] - 1483s 30ms/step - loss: 0.6109 - acc: 0.7830 - val_loss: 0.9642 - val_acc: 0.6800\n",
    "Epoch 13/30\n",
    "50000/50000 [==============================] - 1483s 30ms/step - loss: 0.5864 - acc: 0.7910 - val_loss: 0.9193 - val_acc: 0.6991\n",
    "Epoch 14/30\n",
    "50000/50000 [==============================] - 1438s 29ms/step - loss: 0.5628 - acc: 0.8007 - val_loss: 0.8046 - val_acc: 0.7355\n",
    "Epoch 15/30\n",
    "50000/50000 [==============================] - 1377s 28ms/step - loss: 0.5386 - acc: 0.8088 - val_loss: 0.8892 - val_acc: 0.7091\n",
    "Epoch 16/30\n",
    "50000/50000 [==============================] - 1381s 28ms/step - loss: 0.5174 - acc: 0.8160 - val_loss: 0.8525 - val_acc: 0.7202\n",
    "Epoch 17/30\n",
    "50000/50000 [==============================] - 1379s 28ms/step - loss: 0.4974 - acc: 0.8218 - val_loss: 0.7958 - val_acc: 0.7427\n",
    "Epoch 18/30\n",
    "50000/50000 [==============================] - 1380s 28ms/step - loss: 0.4819 - acc: 0.8287 - val_loss: 0.7817 - val_acc: 0.7417\n",
    "Epoch 19/30\n",
    "50000/50000 [==============================] - 1385s 28ms/step - loss: 0.4561 - acc: 0.8376 - val_loss: 0.8169 - val_acc: 0.7413\n",
    "Epoch 20/30\n",
    "50000/50000 [==============================] - 1384s 28ms/step - loss: 0.4414 - acc: 0.8419 - val_loss: 0.8369 - val_acc: 0.7443\n",
    "Epoch 21/30\n",
    "50000/50000 [==============================] - 1377s 28ms/step - loss: 0.4240 - acc: 0.8489 - val_loss: 0.8434 - val_acc: 0.7311\n",
    "Epoch 22/30\n",
    "50000/50000 [==============================] - 1376s 28ms/step - loss: 0.4102 - acc: 0.8550 - val_loss: 0.8658 - val_acc: 0.7334\n",
    "Epoch 23/30\n",
    "50000/50000 [==============================] - 1430s 29ms/step - loss: 0.3940 - acc: 0.8612 - val_loss: 0.8969 - val_acc: 0.7357\n",
    "Epoch 24/30\n",
    "50000/50000 [==============================] - 1403s 28ms/step - loss: 0.3749 - acc: 0.8650 - val_loss: 0.8846 - val_acc: 0.7356\n",
    "Epoch 25/30\n",
    "50000/50000 [==============================] - 1385s 28ms/step - loss: 0.3688 - acc: 0.8669 - val_loss: 1.0343 - val_acc: 0.7155\n",
    "Epoch 26/30\n",
    "50000/50000 [==============================] - 1382s 28ms/step - loss: 0.3570 - acc: 0.8718 - val_loss: 0.8489 - val_acc: 0.7492\n",
    "Epoch 27/30\n",
    "50000/50000 [==============================] - 1384s 28ms/step - loss: 0.3401 - acc: 0.8774 - val_loss: 0.8902 - val_acc: 0.7419\n",
    "Epoch 28/30\n",
    "50000/50000 [==============================] - 1380s 28ms/step - loss: 0.3309 - acc: 0.8807 - val_loss: 0.9544 - val_acc: 0.7421\n",
    "Epoch 29/30\n",
    "50000/50000 [==============================] - 1389s 28ms/step - loss: 0.3200 - acc: 0.8842 - val_loss: 0.9410 - val_acc: 0.7390\n",
    "Epoch 30/30\n",
    "50000/50000 [==============================] - 1393s 28ms/step - loss: 0.3105 - acc: 0.8879 - val_loss: 0.8948 - val_acc: 0.7517\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
