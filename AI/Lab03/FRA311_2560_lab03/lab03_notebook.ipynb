{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Recognition\n",
    "\n",
    "The objective of this lab is very simple, to recognize objects in images. You will be working with a well-known dataset called CIFAR-10.\n",
    "\n",
    "You can learn more about this dataset and download it here:\n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "In the webpage above, they also included a few publications based on CIFAR-10 data, which showed some amazing accuracies. The worst network on the page (a shallow convolutional neural network) can classify images with rouhgly 75% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Write a function to load data\n",
    "\n",
    "The dataset webpage in the previous section also provide a simple way to load data from your harddrive using pickle. You may use their function for this exercise.\n",
    "\n",
    "Construct two numpy arrays for train images and train labels from data_batch_1 to data_batch_5. Then, construct two numpy arrays for test images, and test labels from test batch file. The original image size is 32 x 32 x 3. You may flatten the arrays so the final arrays are of size 1 x 3072."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = [r\"C:\\Users\\dell\\Desktop\\module8&9\\AI\\Lab03\\cifar-10-batches-py\\data_batch_1\",\n",
    "        r\"C:\\Users\\dell\\Desktop\\module8&9\\AI\\Lab03\\cifar-10-batches-py\\data_batch_2\",\n",
    "        r\"C:\\Users\\dell\\Desktop\\module8&9\\AI\\Lab03\\cifar-10-batches-py\\data_batch_3\",\n",
    "        r\"C:\\Users\\dell\\Desktop\\module8&9\\AI\\Lab03\\cifar-10-batches-py\\data_batch_4\",\n",
    "        r\"C:\\Users\\dell\\Desktop\\module8&9\\AI\\Lab03\\cifar-10-batches-py\\data_batch_5\",\n",
    "        r\"C:\\Users\\dell\\Desktop\\module8&9\\AI\\Lab03\\cifar-10-batches-py\\test_batch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = []\n",
    "label_train = []\n",
    "data_test = []\n",
    "label_test =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(directory)):\n",
    "    if i != len(directory)-1:\n",
    "        raw_data = unpickle(directory[i])\n",
    "        for ind in range(len(raw_data[b'data'])):\n",
    "            data_train.append(raw_data[b'data'][ind])\n",
    "            label_train.append(raw_data[b'labels'][ind])\n",
    "    else:\n",
    "        raw_data = unpickle(directory[i])\n",
    "        for ind in range(len(raw_data[b'data'])):\n",
    "            data_test.append(raw_data[b'data'][ind])\n",
    "            label_test.append(raw_data[b'labels'][ind])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classify Dogs v.s. Cats\n",
    "\n",
    "Letâ€™s start simple by creating logistic regression model to classify images. We will select only two classes of images for this exercise.\n",
    "\n",
    "1. From 50,000 train images and 10,000 test images, we want to reduce the data size. Write code to filter only dog images (label = 3) and cat images (label = 5).\n",
    "2. Create a logistic regression model to classify cats and dogs. Report your accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_data_train = []\n",
    "fil_data_test =[]\n",
    "fil_label_train = []\n",
    "fil_label_test = []\n",
    "\n",
    "for i in range(len(data_train)):\n",
    "    if label_train[i] == 3:\n",
    "        fil_data_train.append(data_train[i])\n",
    "        fil_label_train.append(3)\n",
    "    elif label_train[i] == 5:\n",
    "        fil_data_train.append(data_train[i])\n",
    "        fil_label_train.append(5)\n",
    "\n",
    "for i in range(len(data_test)):\n",
    "    if label_test[i] == 3:\n",
    "        fil_data_test.append(data_test[i])\n",
    "        fil_label_test.append(3)\n",
    "    elif label_test[i] == 5:\n",
    "        fil_data_test.append(data_test[i])\n",
    "        fil_label_test.append(5)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logregr.fit(fil_data_train,fil_label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Logistic Regression model--------------------\n",
      "\n",
      "           The accuracy is 0.5325 or 53.25%\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "acc = logregr.score(fil_data_test,fil_label_test)\n",
    "print('---------------Logistic Regression model--------------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. The Real Challenge\n",
    "\n",
    "The majority of your score for this lab will come from this real challenge. You are going to construct a neural network model to classify 10 classes of images from CIFAR-10 dataset. You will get half the credits for this one if you complete the assignment, and will get another half if you can exceed the target accuracy of 75%. (You may use any combination of sklearn, opencv, or tensorflow to do this exercise).\n",
    "\n",
    "Design at least 3 variants of neural network models. Each model should have different architectures. (Do not vary just a few parameters, the architecture of the network must change in each model). In your notebook, explain your experiments in details and display the accuracy score for each experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. MLP Classifier    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1st Experiment process with preprocessing data\n",
    "    MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(50, 50, 50, 50, 50), learning_rate='constant',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "    accuracy = 0.3612 = 36.12%\n",
    "---------------------------------------------------------------------------\n",
    "2nd Experiment process with preprocessing data\n",
    "    MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(100, 100, 100, 100, 100),\n",
    "       learning_rate='constant', learning_rate_init=0.001, max_iter=500,\n",
    "       momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
    "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
    "       validation_fraction=0.1, verbose=True, warm_start=True)\n",
    "    accuracy = 0.4148\n",
    "---------------------------------------------------------------------------\n",
    "3rd Experiment process with preprocessing data\n",
    "    MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(500, 400, 300, 100, 100),\n",
    "       learning_rate='adaptive', learning_rate_init=0.001, max_iter=500,\n",
    "       momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
    "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
    "       validation_fraction=0.1, verbose=True, warm_start=True)\n",
    "    accuracy = 0.4603\n",
    "---------------------------------------------------------------------------\n",
    "4th Experiment process with preprocessing data\n",
    "    MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(1000, 500, 400), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "    accuracy = 0.5013\n",
    "---------------------------------------------------------------------------\n",
    "5th Experiment *****process with unpreprocessing data\n",
    "    MLP = MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(1000, 500, 400), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "    accuracy = 0.1\n",
    "---------------------------------------------------------------------------\n",
    "6th Experiment ******process with unpreprocessing data\n",
    "    MLP = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(100,100,100,100,100,100,100,100,100,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)    \n",
    "    accuracy = 0.4561\n",
    "---------------------------------------------------------------------------\n",
    "7th Experiment process with preprocessing data\n",
    "    MLP = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(100,100,100,100,100,100,100,100,100,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)  \n",
    "    accuracy = 0.5186\n",
    "---------------------------------------------------------------------------\n",
    "8th Experiment process with preprocessing data\n",
    "    MLP = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(500,400,400,300,300,100,100,100,100,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)  \n",
    "    accuracy = 0.5414\n",
    "---------------------------------------------------------------------------\n",
    "9th Experiment process with preprocessing data\n",
    "    MLP = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(1000,900,800,700,600,500,400,300,200,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)    \n",
    "    accuracy = 0.5390\n",
    "---------------------------------------------------------------------------\n",
    "10th Experiment process with preprocessing data\n",
    "    MLP = MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(1000,900,800,700,600,500,400,300,200,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)  \n",
    "    accuracy = 0.4084\n",
    "---------------------------------------------------------------------------\n",
    "11th Experiment process with preprocessing data\n",
    "    MLP = MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(1000,900,800,700,600,500,400,300,200,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True) \n",
    "    accuracy = 0.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()  \n",
    "scaler.fit(data_train)\n",
    "x_train = scaler.transform(data_train)\n",
    "x_test = scaler.transform(data_test)\n",
    "y_train = label_train\n",
    "y_test = label_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.22694434\n",
      "Validation score: 0.198200\n",
      "Iteration 2, loss = 1.99911828\n",
      "Validation score: 0.244600\n",
      "Iteration 3, loss = 1.91064879\n",
      "Validation score: 0.258400\n",
      "Iteration 4, loss = 1.87713993\n",
      "Validation score: 0.270400\n",
      "Iteration 5, loss = 1.85236123\n",
      "Validation score: 0.287600\n",
      "Iteration 6, loss = 1.82695088\n",
      "Validation score: 0.300000\n",
      "Iteration 7, loss = 1.80129741\n",
      "Validation score: 0.299200\n",
      "Iteration 8, loss = 1.77955007\n",
      "Validation score: 0.310200\n",
      "Iteration 9, loss = 1.75905847\n",
      "Validation score: 0.317400\n",
      "Iteration 10, loss = 1.74100163\n",
      "Validation score: 0.322800\n",
      "Iteration 11, loss = 1.72642825\n",
      "Validation score: 0.318200\n",
      "Iteration 12, loss = 1.71118950\n",
      "Validation score: 0.317800\n",
      "Iteration 13, loss = 1.69264645\n",
      "Validation score: 0.325200\n",
      "Iteration 14, loss = 1.67692253\n",
      "Validation score: 0.326200\n",
      "Iteration 15, loss = 1.66391670\n",
      "Validation score: 0.324400\n",
      "Iteration 16, loss = 1.64757273\n",
      "Validation score: 0.331600\n",
      "Iteration 17, loss = 1.63486347\n",
      "Validation score: 0.333200\n",
      "Iteration 18, loss = 1.62039138\n",
      "Validation score: 0.334400\n",
      "Iteration 19, loss = 1.60492064\n",
      "Validation score: 0.332200\n",
      "Iteration 20, loss = 1.59245606\n",
      "Validation score: 0.335400\n",
      "Iteration 21, loss = 1.57903687\n",
      "Validation score: 0.344200\n",
      "Iteration 22, loss = 1.56454314\n",
      "Validation score: 0.337000\n",
      "Iteration 23, loss = 1.55473056\n",
      "Validation score: 0.343600\n",
      "Iteration 24, loss = 1.53956148\n",
      "Validation score: 0.341200\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "---------------1st MLP Classifier model--------------------\n",
      "\n",
      "------------Process with preprocessing data----------------\n",
      "\n",
      "           The accuracy is 0.3489 or 34.89%\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(50, 50, 50, 50, 50), learning_rate='constant',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "MLP.fit(x_train,y_train)\n",
    "acc = MLP.score(x_test,y_test)\n",
    "print('---------------1st MLP Classifier model--------------------\\n')\n",
    "print('------------Process with preprocessing data----------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.16132990\n",
      "Validation score: 0.218200\n",
      "Iteration 2, loss = 1.95728396\n",
      "Validation score: 0.271000\n",
      "Iteration 3, loss = 1.89104420\n",
      "Validation score: 0.279400\n",
      "Iteration 4, loss = 1.85074483\n",
      "Validation score: 0.284400\n",
      "Iteration 5, loss = 1.81320845\n",
      "Validation score: 0.297800\n",
      "Iteration 6, loss = 1.78033092\n",
      "Validation score: 0.317800\n",
      "Iteration 7, loss = 1.74314279\n",
      "Validation score: 0.330600\n",
      "Iteration 8, loss = 1.71182712\n",
      "Validation score: 0.332600\n",
      "Iteration 9, loss = 1.67787472\n",
      "Validation score: 0.345200\n",
      "Iteration 10, loss = 1.64688579\n",
      "Validation score: 0.363000\n",
      "Iteration 11, loss = 1.61239828\n",
      "Validation score: 0.365600\n",
      "Iteration 12, loss = 1.58338220\n",
      "Validation score: 0.370400\n",
      "Iteration 13, loss = 1.55810643\n",
      "Validation score: 0.379000\n",
      "Iteration 14, loss = 1.53141897\n",
      "Validation score: 0.385200\n",
      "Iteration 15, loss = 1.50315649\n",
      "Validation score: 0.385800\n",
      "Iteration 16, loss = 1.47972339\n",
      "Validation score: 0.390600\n",
      "Iteration 17, loss = 1.45541638\n",
      "Validation score: 0.383400\n",
      "Iteration 18, loss = 1.43208597\n",
      "Validation score: 0.399000\n",
      "Iteration 19, loss = 1.41177662\n",
      "Validation score: 0.399800\n",
      "Iteration 20, loss = 1.38635860\n",
      "Validation score: 0.395000\n",
      "Iteration 21, loss = 1.36956970\n",
      "Validation score: 0.396600\n",
      "Iteration 22, loss = 1.35088598\n",
      "Validation score: 0.396400\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "---------------2nd MLP Classifier model--------------------\n",
      "\n",
      "------------Process with preprocessing data----------------\n",
      "\n",
      "           The accuracy is 0.4043 or 40.43%\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(100, 100, 100, 100, 100),\n",
    "       learning_rate='constant', learning_rate_init=0.001, max_iter=500,\n",
    "       momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
    "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
    "       validation_fraction=0.1, verbose=True, warm_start=True)\n",
    "MLP.fit(x_train,y_train)\n",
    "acc = MLP.score(x_test,y_test)\n",
    "print('---------------2nd MLP Classifier model--------------------\\n')\n",
    "print('------------Process with preprocessing data----------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.08232504\n",
      "Validation score: 0.271000\n",
      "Iteration 2, loss = 1.86101549\n",
      "Validation score: 0.313400\n",
      "Iteration 3, loss = 1.76617446\n",
      "Validation score: 0.343200\n",
      "Iteration 4, loss = 1.68922952\n",
      "Validation score: 0.356400\n",
      "Iteration 5, loss = 1.62788570\n",
      "Validation score: 0.377000\n",
      "Iteration 6, loss = 1.55826722\n",
      "Validation score: 0.407800\n",
      "Iteration 7, loss = 1.49093383\n",
      "Validation score: 0.427000\n",
      "Iteration 8, loss = 1.43200944\n",
      "Validation score: 0.435200\n",
      "Iteration 9, loss = 1.37551202\n",
      "Validation score: 0.452400\n",
      "Iteration 10, loss = 1.32535308\n",
      "Validation score: 0.450800\n",
      "Iteration 11, loss = 1.27455632\n",
      "Validation score: 0.455000\n",
      "Iteration 12, loss = 1.22582603\n",
      "Validation score: 0.463800\n",
      "Iteration 13, loss = 1.18354374\n",
      "Validation score: 0.457800\n",
      "Iteration 14, loss = 1.13371506\n",
      "Validation score: 0.451200\n",
      "Iteration 15, loss = 1.10047128\n",
      "Validation score: 0.465200\n",
      "Iteration 16, loss = 1.05768862\n",
      "Validation score: 0.464200\n",
      "Iteration 17, loss = 1.01474859\n",
      "Validation score: 0.457800\n",
      "Iteration 18, loss = 0.96893284\n",
      "Validation score: 0.460000\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "---------------3rd MLP Classifier model--------------------\n",
      "\n",
      "------------Process with preprocessing data----------------\n",
      "\n",
      "           The accuracy is 0.4552 or 45.519999999999996%\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(500, 400, 300, 100, 100),\n",
    "       learning_rate='adaptive', learning_rate_init=0.001, max_iter=500,\n",
    "       momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
    "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
    "       validation_fraction=0.1, verbose=True, warm_start=True)\n",
    "MLP.fit(x_train,y_train)\n",
    "acc = MLP.score(x_test,y_test)\n",
    "print('---------------3rd MLP Classifier model--------------------\\n')\n",
    "print('------------Process with preprocessing data----------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.82057130\n",
      "Validation score: 0.405600\n",
      "Iteration 2, loss = 1.58599018\n",
      "Validation score: 0.444400\n",
      "Iteration 3, loss = 1.48121840\n",
      "Validation score: 0.458800\n",
      "Iteration 4, loss = 1.40016262\n",
      "Validation score: 0.482600\n",
      "Iteration 5, loss = 1.32957877\n",
      "Validation score: 0.484400\n",
      "Iteration 6, loss = 1.26013949\n",
      "Validation score: 0.492400\n",
      "Iteration 7, loss = 1.20270796\n",
      "Validation score: 0.494000\n",
      "Iteration 8, loss = 1.13538980\n",
      "Validation score: 0.488600\n",
      "Iteration 9, loss = 1.07356223\n",
      "Validation score: 0.491000\n",
      "Iteration 10, loss = 1.01139247\n",
      "Validation score: 0.496600\n",
      "Iteration 11, loss = 0.96158256\n",
      "Validation score: 0.502800\n",
      "Iteration 12, loss = 0.88970001\n",
      "Validation score: 0.499800\n",
      "Iteration 13, loss = 0.84609248\n",
      "Validation score: 0.487200\n",
      "Iteration 14, loss = 0.78371473\n",
      "Validation score: 0.495400\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "---------------4th MLP Classifier model--------------------\n",
      "\n",
      "------------Process with preprocessing data----------------\n",
      "\n",
      "           The accuracy is 0.5025 or 50.24999999999999%\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(1000, 500, 400), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "MLP.fit(x_train,y_train)\n",
    "acc = MLP.score(x_test,y_test)\n",
    "print('---------------4th MLP Classifier model--------------------\\n')\n",
    "print('------------Process with preprocessing data----------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.31459930\n",
      "Validation score: 0.106000\n",
      "Iteration 2, loss = 2.31138424\n",
      "Validation score: 0.102200\n",
      "Iteration 3, loss = 2.31095076\n",
      "Validation score: 0.102200\n",
      "Iteration 4, loss = 2.31079531\n",
      "Validation score: 0.093800\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "---------------5th MLP Classifier model--------------------\n",
      "\n",
      "-----------Process with unpreprocessing data---------------\n",
      "\n",
      "           The accuracy is 0.1 or 10.0%\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(1000, 500, 400), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "MLP.fit(data_train,label_train)\n",
    "acc = MLP.score(data_test,label_test)\n",
    "print('---------------5th MLP Classifier model--------------------\\n')\n",
    "print('-----------Process with unpreprocessing data---------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.57371491\n",
      "Validation score: 0.297400\n",
      "Iteration 2, loss = 1.87283730\n",
      "Validation score: 0.314800\n",
      "Iteration 3, loss = 1.79168671\n",
      "Validation score: 0.370400\n",
      "Iteration 4, loss = 1.71368339\n",
      "Validation score: 0.380200\n",
      "Iteration 5, loss = 1.67788369\n",
      "Validation score: 0.402400\n",
      "Iteration 6, loss = 1.65500863\n",
      "Validation score: 0.404200\n",
      "Iteration 7, loss = 1.61569048\n",
      "Validation score: 0.422800\n",
      "Iteration 8, loss = 1.60146171\n",
      "Validation score: 0.397400\n",
      "Iteration 9, loss = 1.57219568\n",
      "Validation score: 0.425800\n",
      "Iteration 10, loss = 1.56941596\n",
      "Validation score: 0.430800\n",
      "Iteration 11, loss = 1.54785734\n",
      "Validation score: 0.429000\n",
      "Iteration 12, loss = 1.54447256\n",
      "Validation score: 0.431600\n",
      "Iteration 13, loss = 1.51751656\n",
      "Validation score: 0.416400\n",
      "Iteration 14, loss = 1.50252326\n",
      "Validation score: 0.445800\n",
      "Iteration 15, loss = 1.50294776\n",
      "Validation score: 0.426400\n",
      "Iteration 16, loss = 1.48918935\n",
      "Validation score: 0.457000\n",
      "Iteration 17, loss = 1.46732980\n",
      "Validation score: 0.451000\n",
      "Iteration 18, loss = 1.46225846\n",
      "Validation score: 0.440000\n",
      "Iteration 19, loss = 1.45664858\n",
      "Validation score: 0.461400\n",
      "Iteration 20, loss = 1.44985631\n",
      "Validation score: 0.435600\n",
      "Iteration 21, loss = 1.44796199\n",
      "Validation score: 0.470600\n",
      "Iteration 22, loss = 1.42836826\n",
      "Validation score: 0.476800\n",
      "Iteration 23, loss = 1.42339086\n",
      "Validation score: 0.459600\n",
      "Iteration 24, loss = 1.41812013\n",
      "Validation score: 0.468000\n",
      "Iteration 25, loss = 1.40710729\n",
      "Validation score: 0.469200\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "---------------6th MLP Classifier model--------------------\n",
      "\n",
      "-----------Process with unpreprocessing data---------------\n",
      "\n",
      "           The accuracy is 0.4725 or 47.25%\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(100,100,100,100,100,100,100,100,100,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "MLP.fit(data_train,label_train)\n",
    "acc = MLP.score(data_test,label_test)\n",
    "print('---------------6th MLP Classifier model--------------------\\n')\n",
    "print('-----------Process with unpreprocessing data---------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.81686909\n",
      "Validation score: 0.424800\n",
      "Iteration 2, loss = 1.56988781\n",
      "Validation score: 0.458200\n",
      "Iteration 3, loss = 1.46132671\n",
      "Validation score: 0.473600\n",
      "Iteration 4, loss = 1.38051928\n",
      "Validation score: 0.479200\n",
      "Iteration 5, loss = 1.32457125\n",
      "Validation score: 0.486000\n",
      "Iteration 6, loss = 1.27309907\n",
      "Validation score: 0.497600\n",
      "Iteration 7, loss = 1.22442936\n",
      "Validation score: 0.503200\n",
      "Iteration 8, loss = 1.18087734\n",
      "Validation score: 0.502400\n",
      "Iteration 9, loss = 1.14142853\n",
      "Validation score: 0.498800\n",
      "Iteration 10, loss = 1.10579353\n",
      "Validation score: 0.505200\n",
      "Iteration 11, loss = 1.07034066\n",
      "Validation score: 0.500000\n",
      "Iteration 12, loss = 1.02910177\n",
      "Validation score: 0.503200\n",
      "Iteration 13, loss = 0.99489128\n",
      "Validation score: 0.507600\n",
      "Iteration 14, loss = 0.97434128\n",
      "Validation score: 0.503400\n",
      "Iteration 15, loss = 0.93713493\n",
      "Validation score: 0.507600\n",
      "Iteration 16, loss = 0.91389310\n",
      "Validation score: 0.502000\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "---------------7th MLP Classifier model--------------------\n",
      "\n",
      "-----------Process with preprocessing data---------------\n",
      "\n",
      "           The accuracy is 0.512 or 51.2%\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(100,100,100,100,100,100,100,100,100,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "MLP.fit(x_train,y_train)\n",
    "acc = MLP.score(x_test,y_test)\n",
    "print('---------------7th MLP Classifier model--------------------\\n')\n",
    "print('-----------Process with preprocessing data---------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.77207536\n",
      "Validation score: 0.417800\n",
      "Iteration 2, loss = 1.53358134\n",
      "Validation score: 0.448600\n",
      "Iteration 3, loss = 1.41074790\n",
      "Validation score: 0.467600\n",
      "Iteration 4, loss = 1.31799205\n",
      "Validation score: 0.476600\n",
      "Iteration 5, loss = 1.23393611\n",
      "Validation score: 0.490400\n",
      "Iteration 6, loss = 1.15487731\n",
      "Validation score: 0.516200\n",
      "Iteration 7, loss = 1.08659650\n",
      "Validation score: 0.516400\n",
      "Iteration 8, loss = 1.01317002\n",
      "Validation score: 0.510600\n",
      "Iteration 9, loss = 0.94471309\n",
      "Validation score: 0.513000\n",
      "Iteration 10, loss = 0.88055017\n",
      "Validation score: 0.515800\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "---------------8th MLP Classifier model--------------------\n",
      "\n",
      "-----------Process with preprocessing data---------------\n",
      "\n",
      "           The accuracy is 0.523 or 52.300000000000004%\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(500,400,400,300,300,100,100,100,100,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "MLP.fit(x_train,y_train)\n",
    "acc = MLP.score(x_test,y_test)\n",
    "print('---------------8th MLP Classifier model--------------------\\n')\n",
    "print('-----------Process with preprocessing data---------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.78198143\n",
      "Validation score: 0.408800\n",
      "Iteration 2, loss = 1.55618091\n",
      "Validation score: 0.463800\n",
      "Iteration 3, loss = 1.43869108\n",
      "Validation score: 0.467000\n",
      "Iteration 4, loss = 1.34106875\n",
      "Validation score: 0.500800\n",
      "Iteration 5, loss = 1.26448479\n",
      "Validation score: 0.520000\n",
      "Iteration 6, loss = 1.18020876\n",
      "Validation score: 0.516000\n",
      "Iteration 7, loss = 1.10483650\n",
      "Validation score: 0.522400\n",
      "Iteration 8, loss = 1.02434141\n",
      "Validation score: 0.536800\n",
      "Iteration 9, loss = 0.96159330\n",
      "Validation score: 0.548800\n",
      "Iteration 10, loss = 0.88866472\n",
      "Validation score: 0.534800\n",
      "Iteration 11, loss = 0.82882116\n",
      "Validation score: 0.545000\n",
      "Iteration 12, loss = 0.75859975\n",
      "Validation score: 0.538000\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "---------------9th MLP Classifier model--------------------\n",
      "\n",
      "-----------Process with preprocessing data---------------\n",
      "\n",
      "           The accuracy is 0.5428 or 54.279999999999994%\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(1000,900,800,700,600,500,400,300,200,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "MLP.fit(x_train,y_train)\n",
    "acc = MLP.score(x_test,y_test)\n",
    "print('---------------9th MLP Classifier model--------------------\\n')\n",
    "print('-----------Process with preprocessing data---------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.96128042\n",
      "Validation score: 0.319800\n",
      "Iteration 2, loss = 1.85890659\n",
      "Validation score: 0.344200\n",
      "Iteration 3, loss = 1.79993962\n",
      "Validation score: 0.323800\n",
      "Iteration 4, loss = 1.79609841\n",
      "Validation score: 0.344800\n",
      "Iteration 5, loss = 1.75482530\n",
      "Validation score: 0.354200\n",
      "Iteration 6, loss = 1.71542905\n",
      "Validation score: 0.356400\n",
      "Iteration 7, loss = 1.69040880\n",
      "Validation score: 0.377400\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(1000,900,800,700,600,500,400,300,200,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "MLP.fit(x_train,y_train)\n",
    "acc = MLP.score(x_test,y_test)\n",
    "print('---------------10th MLP Classifier model--------------------\\n')\n",
    "print('-----------Process with preprocessing data------------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
    "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(1000,900,800,700,600,500,400,300,200,100), learning_rate='adaptive',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=True, warm_start=True)\n",
    "MLP.fit(x_train,y_train)\n",
    "acc = MLP.score(x_test,y_test)\n",
    "print('---------------11th MLP Classifier model--------------------\\n')\n",
    "print('-----------Process with preprocessing data------------------\\n')\n",
    "print('           The accuracy is '+str(acc)+' or '+str(acc*100)+'%'+'\\n')\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Convolution Neural Network(CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x3d_train = np.array(data_train).reshape(np.array(data_train).shape[0],3,32,32)\n",
    "x3d_test = np.array(data_test).reshape(np.array(data_test).shape[0],3,32,32)\n",
    "\n",
    "y_train =  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
